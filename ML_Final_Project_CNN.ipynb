{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9314ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as nmp\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as pltIm\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c935f10",
   "metadata": {},
   "source": [
    "# Downloading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74162636",
   "metadata": {},
   "outputs": [],
   "source": [
    "(Xtrain,Ytrain),(Xtest,Ytest) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeaad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(12):\n",
    "    pltIm.subplot(3,4,index+1)\n",
    "    pltIm.imshow(Xtrain[index])\n",
    "pltIm.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544a06d8",
   "metadata": {},
   "source": [
    "# Normalize Pixel Data and Change Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8eb27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizePixelDataAndChangeType(train,test):\n",
    "    normalizeAndTypeTrain = train.astype('float32')\n",
    "    normalizeAndTypeTest = test.astype('float32')\n",
    "    \n",
    "    normalizeAndTypeTrain = normalizeAndTypeTrain / 255.0 - 0.5\n",
    "    normalizeAndTypeTest = normalizeAndTypeTest / 255.0 - 0.5\n",
    "    \n",
    "    return normalizeAndTypeTrain , normalizeAndTypeTest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a2abd3",
   "metadata": {},
   "source": [
    "# Convolutional layer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01ff58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class convolutionLayerOperation:\n",
    "    def __init__(self,numberOfFilters, sizeOfFilter):\n",
    "        self.numberOfFilters = numberOfFilters\n",
    "        self.sizeOfFilter = sizeOfFilter\n",
    "        self.convolutionFilter = nmp.random.randn(self.numberOfFilters,self.sizeOfFilter,self.sizeOfFilter) / (self.sizeOfFilter * self.sizeOfFilter)\n",
    "    def imagePatch(self):\n",
    "        for vIndex in range(self.heightOfInput - self.sizeOfFilter + 1):\n",
    "            for hIndex in range(self.widthOfInput - self.sizeOfFilter + 1):\n",
    "                    imagePatch = self.imageInput[vIndex : (vIndex + self.sizeOfFilter) , hIndex : (hIndex + self.sizeOfFilter) ]\n",
    "                    yield imagePatch,vIndex,hIndex\n",
    "    \n",
    "    def forwardPropagation(self,imageInput):\n",
    "        self.imageInput = imageInput\n",
    "        self.heightOfInput , self.widthOfInput = self.imageInput.shape\n",
    "        convolutionOutput = nmp.zeros((self.heightOfInput - self.sizeOfFilter + 1, self.widthOfInput - self.sizeOfFilter + 1, self.numberOfFilters))\n",
    "        \n",
    "        for imagePatch , vIndex , hIndex in self.imagePatch():\n",
    "            for filter_ in range(self.numberOfFilters):\n",
    "                convolutionOutput[vIndex,hIndex] = nmp.sum(imagePatch * self.convolutionFilter,axis = (1,2))\n",
    "        return convolutionOutput\n",
    "    \n",
    "    def backPropagation(self,dLossOutPrev,learningRate):\n",
    "        dLossParams = nmp.zeros(self.convolutionFilter.shape)\n",
    "        for imagePatch , vIndex,hIndex in self.imagePatch():\n",
    "            for itrFilter in range(self.numberOfFilters):\n",
    "                dLossParams[itrFilter] += imagePatch * dLossOutPrev[vIndex,hIndex,itrFilter]\n",
    "        \n",
    "        self.convolutionFilter = self.convolutionFilter - learningRate * dLossParams\n",
    "        return dLossParams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f66d0a",
   "metadata": {},
   "source": [
    "# Pooling Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce724307",
   "metadata": {},
   "outputs": [],
   "source": [
    "class pooling:\n",
    "    def __init__(self,sizeOfFilter,typePooling):\n",
    "        self.sizeOfFilter = sizeOfFilter\n",
    "        self.typePooling = typePooling\n",
    "        \n",
    "\n",
    "    def calculateNewDimensionAndImagePatch(self):\n",
    "        \n",
    "        for vIndex in range(self.updatedHeight):\n",
    "            for hIndex in range(self.updatedWidth):\n",
    "                imagePatch = self.imageInput[vIndex * self.sizeOfFilter : vIndex * self.sizeOfFilter + self.sizeOfFilter , hIndex * self.sizeOfFilter : hIndex * self.sizeOfFilter + self.sizeOfFilter]\n",
    "                yield imagePatch,vIndex,hIndex\n",
    "    \n",
    "    def poolingOperation(self):\n",
    "        \n",
    "        poolOutput = nmp.zeros((self.updatedHeight,self.updatedWidth,self.numberOfFilters))\n",
    "        \n",
    "        if self.typePooling == \"Max\":\n",
    "            for imagePatch , vIndex, hIndex in self.calculateNewDimensionAndImagePatch():\n",
    "                poolOutput[vIndex,hIndex] = nmp.amax(imagePatch,axis = (0,1))\n",
    "        else:\n",
    "            for imagePatch , vIndex, hIndex in self.calculateNewDimensionAndImagePatch():\n",
    "                poolOutput[vIndex,hIndex] = nmp.mean(imagePatch,axis = (0,1))\n",
    "        \n",
    "        return poolOutput\n",
    "    \n",
    "    def forwardPropagation(self,imageInput):\n",
    "        self.imageInput = imageInput\n",
    "        self.heightInput , self.widthInput , self.numberOfFilters = self.imageInput.shape[0], self.imageInput.shape[1],self.imageInput.shape[2]\n",
    "        self.updatedHeight = self.heightInput // self.sizeOfFilter\n",
    "        self.updatedWidth = self.widthInput // self.sizeOfFilter\n",
    "        \n",
    "        poolOutput = self.poolingOperation()\n",
    "        \n",
    "        return poolOutput\n",
    "    \n",
    "    def backPropagation(self,dLossOutPrev):\n",
    "        \n",
    "        dLossMaxPool = nmp.zeros(self.imageInput.shape)\n",
    "        \n",
    "        for imagePatch , vIndex, hIndex in self.calculateNewDimensionAndImagePatch():\n",
    "            heightImagePatch , widthImagePatch , numberOfFilters = imagePatch.shape\n",
    "            maxVal = nmp.amax(imagePatch,axis = (0,1))\n",
    "            for vIndex_ in range(heightImagePatch):\n",
    "                for hIndex_ in range(widthImagePatch):\n",
    "                    for filter_ in range(numberOfFilters):\n",
    "                        if imagePatch[vIndex_,hIndex_,filter_] == maxVal[filter_]:\n",
    "                            dLossMaxPool[vIndex * self.sizeOfFilter + vIndex_ , hIndex * self.sizeOfFilter + hIndex_,filter_] = dLossOutPrev[vIndex,hIndex,filter_]\n",
    "                    \n",
    "            return dLossMaxPool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc964f72",
   "metadata": {},
   "source": [
    "# Softmax Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410f7f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class softmax:\n",
    "    def __init__(self,inputSoftmax,softmaxNode):\n",
    "        self.weightsLayer = nmp.random.randn(inputSoftmax,softmaxNode)/inputSoftmax\n",
    "        self.bias = nmp.zeros(softmaxNode)\n",
    "    \n",
    "    def forwardPropagation(self,imageInput):\n",
    "        self.imageInput = imageInput\n",
    "        self.inputShape = self.imageInput.shape\n",
    "        \n",
    "        self.flattenImage = self.imageInput.flatten()\n",
    "        self.outputSoftmaxValue = nmp.dot(self.flattenImage,self.weightsLayer) + self.bias\n",
    "        self.outputSoftmaxValue = nmp.exp(self.outputSoftmaxValue)\n",
    "        return self.outputSoftmaxValue / nmp.sum(self.outputSoftmaxValue,axis = 0)\n",
    "    \n",
    "    def backPropagation(self,dLOut,learningRate):\n",
    "        for index,grad in enumerate(dLOut):\n",
    "            if grad == 0:\n",
    "                continue\n",
    "            \n",
    "            totalSum = nmp.sum(self.outputSoftmaxValue,axis = 0)\n",
    "            \n",
    "            dydz = - self.outputSoftmaxValue[index] * self.outputSoftmaxValue / (totalSum ** 2)\n",
    "            dydz[index] = self.outputSoftmaxValue[index]*(totalSum - self.outputSoftmaxValue[index]) / (totalSum ** 2)\n",
    "            \n",
    "            dzdw = self.flattenImage\n",
    "            dzdb = 1\n",
    "            dzdinput = self.weightsLayer\n",
    "            \n",
    "            dLdz = grad * dydz\n",
    "            \n",
    "            dLdw = dzdw[nmp.newaxis].T @ dLdz[nmp.newaxis]\n",
    "            dLdb = dLdz * dzdb\n",
    "            dLdinput = dzdinput @ dLdz\n",
    "        \n",
    "        \n",
    "        self.weightsLayer = self.weightsLayer - learningRate * dLdw\n",
    "        self.bias = self.bias - learningRate * dLdb\n",
    "        \n",
    "        return dLdinput.reshape(self.imageInput.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f48cee",
   "metadata": {},
   "source": [
    "# Fully Connected Layer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78ff65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fullyConnectedLayer:\n",
    "    \n",
    "    def __init__(self,inputSize,outputSize):\n",
    "    \n",
    "        self.weightsLayer = nmp.random.randn(inputSize,outputSize) / (inputSize * outputSize)\n",
    "\n",
    "        self.bias = nmp.random.rand(1, outputSize)\n",
    "        \n",
    "    \n",
    "    def forwardPropagation(self,inputData):\n",
    "        self.inputData = inputData\n",
    "        self.output = nmp.dot(self.inputData,self.weightsLayer) + self.bias\n",
    "        return self.output\n",
    "    \n",
    "    def backPropagation(self,outputError,learningRate):\n",
    "        inputError = nmp.dot(outputError,self.weightsLayer.T)\n",
    "        \n",
    "        weightsError = nmp.dot(self.inputData.T,outputError)\n",
    "        \n",
    "        self.weightsLayer = self.weightsLayer - learningRate * weightsError\n",
    "        self.bias = self.bias - learningRate * outputError\n",
    "        return inputError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39401401",
   "metadata": {},
   "source": [
    "# Activation Layer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb88c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationLayer():\n",
    "    def __init__(self,typeAct = 'ReLU'):\n",
    "        self.typeAct = typeAct\n",
    "    \n",
    "    def forwardPropagation(self,inputData):\n",
    "        self.inputActivation = inputData\n",
    "        self.output = self.activationFunction(self.inputActivation)\n",
    "        return self.output\n",
    "    \n",
    "    def activationFunction(self,inputMatrix):\n",
    "        if self.typeAct == 'sigmoid':\n",
    "            return 1 / (1 + nmp.exp(-inputMatrix))\n",
    "        elif self.typeAct == 'tanh':\n",
    "            return nmp.tanh(inputMatrix)\n",
    "        else:\n",
    "            inputMatrix[inputMatrix < 0] = 0\n",
    "            return inputMatrix\n",
    "        \n",
    "    def firstOrderDerivative(self,inputMatrix):\n",
    "        if self.typeAct == 'sigmoid':\n",
    "            return inputMatrix * (1 - inputMatrix)\n",
    "        elif self.typeAct == 'tanh':\n",
    "            return 1 - inputMatrix ** 2\n",
    "        else:\n",
    "            inputMatrix[inputMatrix < 0] = 0\n",
    "            inputMatrix[inputMatrix >= 1] = 1\n",
    "            return inputMatrix\n",
    "        \n",
    "    def backPropagation(self,outputError,learningRate):\n",
    "        \n",
    "        outputD = self.firstOrderDerivative(self.inputActivation) * outputError\n",
    "        return outputD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b93fe66",
   "metadata": {},
   "source": [
    "# Flatten Layer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f8e052",
   "metadata": {},
   "outputs": [],
   "source": [
    "class flattenLayer():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forwardPropagation(self, inputData):\n",
    "        self.input = inputData\n",
    "        self.output = inputData.flatten().reshape((1,-1))\n",
    "        return self.output\n",
    "    \n",
    "    def backPropagation(self, outputError, learningRate):\n",
    "        return outputError.reshape(self.input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7e53e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d0d1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = convolutionLayerOperation(20,3)\n",
    "ACLayer1 = ActivationLayer('ReLU')\n",
    "mPool1 = pooling(2,'Max')\n",
    "\n",
    "flattenL1 = flattenLayer()\n",
    "FC1 = fullyConnectedLayer(15*15*20,100)\n",
    "ACLayer2 = ActivationLayer('ReLU')\n",
    "softmax1 = softmax(100,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9bf6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutionForwardPropagation(image,conv,aCLayer,pool):\n",
    "    \n",
    "    output = conv.forwardPropagation(image)\n",
    "    output = aCLayer.forwardPropagation(output)\n",
    "    output = pool.forwardPropagation(output)  \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2570c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateLossAndAccuracy(output,lbl):\n",
    "    crossEntropyLoss = -nmp.log(output[lbl])\n",
    "    accuracyEvaluation = 1 if nmp.argmax(output) == lbl else 0\n",
    "    \n",
    "    return crossEntropyLoss, accuracyEvaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a75846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingCNN(image,lbl,learningRate = 0.05):\n",
    "    \n",
    "    #Forward\n",
    "    output = convolutionForwardPropagation(image,conv1,ACLayer1,mPool1)\n",
    "    output = flattenL1.forwardPropagation(output)\n",
    "    output = FC1.forwardPropagation(output)\n",
    "    output = ACLayer2.forwardPropagation(output)\n",
    "    output = softmax1.forwardPropagation(output)\n",
    "    \n",
    "    loss, accuracy = calculateLossAndAccuracy(output,lbl)\n",
    "    \n",
    "    #Calculate Gradient\n",
    "    gradient = nmp.zeros(10)\n",
    "    gradient[lbl] = -1/ output[lbl]\n",
    "    \n",
    "    gradBack = softmax1.backPropagation(gradient,learningRate)\n",
    "    gradBack = ACLayer2.backPropagation(gradBack,learningRate)\n",
    "    gradBack = FC1.backPropagation(gradBack,learningRate)\n",
    "    gradBack = flattenL1.backPropagation(gradBack,learningRate)\n",
    "    \n",
    "    gradBack = mPool1.backPropagation(gradBack)\n",
    "    gradBack = ACLayer1.backPropagation(gradBack,learningRate)\n",
    "    gradBack = conv1.backPropagation(gradBack,learningRate)\n",
    "    \n",
    "    return loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f81feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingLoop(epoch,Xtrain,Ytrain,learningRate):\n",
    "    for epoch_ in range(epoch):\n",
    "        print(f\"Epoch : {epoch_ + 1}\")\n",
    "        loss = 0\n",
    "        numCorr = 0\n",
    "\n",
    "        tempData = list(zip(Xtrain,Ytrain))\n",
    "        random.shuffle(tempData)\n",
    "        Xtrain , Ytrain = zip(*tempData)\n",
    "        Xtrain,Ytrain = list(Xtrain),list(Ytrain)\n",
    "    \n",
    "        for index , (image,lbl) in enumerate(zip(Xtrain,Ytrain)):\n",
    "        \n",
    "            if index % 125 == 0:\n",
    "                print(f\"{index+1} steps out of 100:Average Loss {loss/100} and Accuracy {numCorr/125 * 100}%\")\n",
    "                loss = 0\n",
    "                numCorr = 0\n",
    "        \n",
    "            loss_ , accu = trainingCNN(image,lbl,learningRate)\n",
    "            loss += loss_\n",
    "            numCorr += accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2f91d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "XtrainG = []\n",
    "XtestG = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbdae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToGray(imageData,type_ = \"train\"):\n",
    "    \n",
    "    for imageIn in imageData:\n",
    "        redComponent, gComponent, bComponent = imageIn[:,:,0], imageIn[:,:,1], imageIn[:,:,2]\n",
    "        imageIn = 0.2989 * redComponent + 0.5870 * gComponent + 0.1140 * bComponent\n",
    "        \n",
    "        if(type_ == \"train\"):\n",
    "            XtrainG.append(imageIn)\n",
    "        else:\n",
    "            XtestG.append(imageIn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eea1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "XtrainTL , XtestTL = normalizePixelDataAndChangeType(Xtrain,Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3c637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "convertToGray(XtrainTL,\"train\")\n",
    "convertToGray(XtestTL,\"test\")\n",
    "XtrainG = XtrainG[:10000]\n",
    "YtrainG = Ytrain[:10000]\n",
    "XtestG = XtestG[:10000]\n",
    "YtestG = Ytest[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d535aef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(XtrainG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96f06c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "XtrainG[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f24d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingLoop(10,XtrainG,YtrainG,0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84d94d1",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23704758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fbcff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageSize = [32,32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3f8524",
   "metadata": {},
   "outputs": [],
   "source": [
    "vggModel = VGG19(input_shape = imageSize + [3] ,weights = 'imagenet',include_top = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c343ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "vggModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdc689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for individualLayer in vggModel.layers:\n",
    "    individualLayer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7000e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "layersX = tf.keras.layers.Flatten()(vggModel.output)\n",
    "predicOutputOf = tf.keras.layers.Dense(10,activation = 'softmax')(layersX)\n",
    "changedPretainedModel = tf.keras.models.Model(inputs = vggModel.input,outputs = predicOutputOf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d811c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerUsedIntheModel = keras.optimizers.Adam(learning_rate = 0.05)\n",
    "metricsUsedInTheModel = [\"accuracy\"]\n",
    "changedPretainedModel.compile(optimizer = optimizerUsedIntheModel ,loss = 'sparse_categorical_crossentropy',metrics = metricsUsedInTheModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56200aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "changedPretainedModel.fit(XtrainTL,Ytrain,validation_data = (XtestTL,Ytest),epochs = 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (Tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
